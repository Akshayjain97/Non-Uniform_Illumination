{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47385,
     "status": "ok",
     "timestamp": 1682065596806,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "XZzf-kMNhZ1W",
    "outputId": "8345e042-34b0-4cc6-b303-01facb267d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33098,
     "status": "ok",
     "timestamp": 1682065629896,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "iizIHJR_aL5a",
    "outputId": "2961a45c-6110-48ab-ef5d-80c72a5389fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9a61f6d9324a29bb43e30e5f96f986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/256_ObjectCategories.tar to /home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset Caltech256\n",
       "    Number of datapoints: 30607\n",
       "    Root location: /home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.datasets.Caltech256(root='/home/cvblgita/akshay/AdaNorm-main/Caltech256', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1682065631431,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "q2XaL7-sKjoR"
   },
   "outputs": [],
   "source": [
    "!python3 /home/cvblgita/akshay/AdaNorm-main/Caltech256/Train_Test_Split.py --data_path='/home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/256_ObjectCategories' --test_data_path_to_save='/home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/test' --train_ratio=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1682065631432,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "hd-gwOyKySpK",
    "outputId": "79ca6f5a-a419-485a-dbef-859814eb44f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/256_ObjectCategories\n"
     ]
    }
   ],
   "source": [
    "cd /home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/256_ObjectCategories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1682065631432,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "tNmZZTZd8in6",
    "outputId": "d79b8f11-6d8b-4637-900d-8e8fbb0f0236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/home/cvblgita/akshay/AdaNorm-main/Caltech256/Test_labels.txt' mode='a' encoding='UTF-8'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('/home/cvblgita/akshay/AdaNorm-main/Caltech256/Train_labels.txt','a')\n",
    "open('/home/cvblgita/akshay/AdaNorm-main/Caltech256/Test_labels.txt','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ~+ -iname \"*.jpg\" > /home/cvblgita/akshay/AdaNorm-main/Caltech256/Train_labels.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1682065631922,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "EdAlA1zA6UOi",
    "outputId": "aed4567c-bb22-4cdb-9f12-9611b107300d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/test\n"
     ]
    }
   ],
   "source": [
    "cd /home/cvblgita/akshay/AdaNorm-main/Caltech256/caltech256/test\n",
    "256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1682065631923,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "B-mwa9W35qrD"
   },
   "outputs": [],
   "source": [
    "!ls -d -1 \"$PWD/\"*.*/*_* > /home/cvblgita/akshay/AdaNorm-main/Caltech256/Test_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ~+ -iname \"*.jpg\" > /home/cvblgita/akshay/AdaNorm-main/Caltech256/Test_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1682065631923,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "3p9mzExfvrLI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "name = '/home/cvblgita/akshay/AdaNorm-main/Caltech256/Train_labels.txt'\n",
    "final = name.split('.')[0]\n",
    "os.rename(name,final+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1682065631924,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "YSemUGSf7TJd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "name = '/home/cvblgita/akshay/AdaNorm-main/Caltech256/Test_labels.txt'\n",
    "final = name.split('.')[0]\n",
    "os.rename(name,final+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi1hJPED8Fi3"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714795,
     "status": "ok",
     "timestamp": 1682070200390,
     "user": {
      "displayName": "Akshay Jain",
      "userId": "02624051612458467316"
     },
     "user_tz": -330
    },
    "id": "B7-54WlKmMPr",
    "outputId": "3e3f16ea-f185-4eac-c8e2-117f2a3e9b3e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Building model..\n",
      "/home/cvblgita/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "\n",
      "Epoch: 0\n",
      " [================================================================>]  Step: 1s702ms | Tot: 1m36s | Loss: 4.987 | Acc: 8.289% (2030/2448 383/383  \n",
      " [================================================================>]  Step: 445ms | Tot: 18s604ms | Loss: 4.708 | Acc: 11.396% (697/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [================================================================>]  Step: 143ms | Tot: 1m32s | Loss: 4.476 | Acc: 13.337% (3266/2448 383/383    \n",
      " [================================================================>]  Step: 117ms | Tot: 15s172ms | Loss: 4.269 | Acc: 15.925% (974/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      " [================================================================>]  Step: 38ms | Tot: 1m33s | Loss: 4.140 | Acc: 17.767% (4351/2448 383/383     \n",
      " [================================================================>]  Step: 125ms | Tot: 15s426ms | Loss: 4.092 | Acc: 19.653% (1202/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      " [================================================================>]  Step: 218ms | Tot: 1m32s | Loss: 3.853 | Acc: 21.487% (5262/2448 383/383    \n",
      " [================================================================>]  Step: 11ms | Tot: 15s80ms | Loss: 3.790 | Acc: 22.564% (1380/611 96/96   \n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      " [================================================================>]  Step: 273ms | Tot: 1m34s | Loss: 3.594 | Acc: 24.840% (6083/2448 383/383    \n",
      " [================================================================>]  Step: 118ms | Tot: 15s174ms | Loss: 3.583 | Acc: 25.899% (1584/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      " [================================================================>]  Step: 182ms | Tot: 1m32s | Loss: 3.361 | Acc: 28.376% (6949/2448 383/383 3  \n",
      " [================================================================>]  Step: 12ms | Tot: 15s607ms | Loss: 3.429 | Acc: 28.221% (1726/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      " [================================================================>]  Step: 39ms | Tot: 1m33s | Loss: 3.155 | Acc: 31.688% (7760/2448 383/383     \n",
      " [================================================================>]  Step: 121ms | Tot: 15s260ms | Loss: 3.246 | Acc: 31.606% (1933/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      " [================================================================>]  Step: 137ms | Tot: 1m32s | Loss: 2.977 | Acc: 34.709% (8500/2448 383/383    \n",
      " [================================================================>]  Step: 12ms | Tot: 15s964ms | Loss: 3.132 | Acc: 33.519% (2050/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      " [================================================================>]  Step: 264ms | Tot: 1m33s | Loss: 2.802 | Acc: 37.964% (9297/2448 383/383    \n",
      " [================================================================>]  Step: 11ms | Tot: 15s719ms | Loss: 3.079 | Acc: 34.091% (2085/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      " [================================================================>]  Step: 37ms | Tot: 1m33s | Loss: 2.645 | Acc: 40.635% (9951/2448 383/383     \n",
      " [================================================================>]  Step: 119ms | Tot: 15s1ms | Loss: 2.940 | Acc: 36.642% (2241/611 96/96   \n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      " [================================================================>]  Step: 60ms | Tot: 1m32s | Loss: 2.507 | Acc: 43.158% (10569/2448 383/383     \n",
      " [================================================================>]  Step: 11ms | Tot: 15s828ms | Loss: 2.918 | Acc: 37.148% (2272/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      " [================================================================>]  Step: 25ms | Tot: 1m32s | Loss: 2.386 | Acc: 45.363% (11109/2448 383/383    \n",
      " [================================================================>]  Step: 12ms | Tot: 15s128ms | Loss: 2.837 | Acc: 39.781% (2433/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      " [================================================================>]  Step: 324ms | Tot: 1m34s | Loss: 2.264 | Acc: 47.728% (11688/2448 383/383   \n",
      " [================================================================>]  Step: 126ms | Tot: 15s12ms | Loss: 2.819 | Acc: 39.307% (2404/611 96/96  \n",
      "\n",
      "Epoch: 13\n",
      " [================================================================>]  Step: 37ms | Tot: 1m33s | Loss: 2.156 | Acc: 49.483% (12118/2448 383/383     \n",
      " [================================================================>]  Step: 12ms | Tot: 15s55ms | Loss: 2.724 | Acc: 41.334% (2528/611 96/96   \n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      " [================================================================>]  Step: 40ms | Tot: 1m34s | Loss: 2.031 | Acc: 51.966% (12726/2448 383/383    \n",
      " [================================================================>]  Step: 12ms | Tot: 14s981ms | Loss: 2.641 | Acc: 42.544% (2602/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      " [================================================================>]  Step: 186ms | Tot: 1m33s | Loss: 1.952 | Acc: 53.595% (13125/2448 383/383   3 \n",
      " [================================================================>]  Step: 12ms | Tot: 15s309ms | Loss: 2.660 | Acc: 42.724% (2613/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      " [================================================================>]  Step: 191ms | Tot: 1m32s | Loss: 1.846 | Acc: 55.927% (13696/2448 383/383   \n",
      " [================================================================>]  Step: 12ms | Tot: 15s875ms | Loss: 2.633 | Acc: 43.165% (2640/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      " [================================================================>]  Step: 221ms | Tot: 1m35s | Loss: 1.756 | Acc: 57.418% (14061/2448 383/383 3 \n",
      " [================================================================>]  Step: 12ms | Tot: 16s780ms | Loss: 2.646 | Acc: 44.130% (2699/611 96/96  \n",
      "Saving..\n",
      "\n",
      "Epoch: 18\n",
      " [================================================================>]  Step: 39ms | Tot: 1m36s | Loss: 1.673 | Acc: 59.525% (14577/2448 383/383    \n",
      " [================================================================>]  Step: 123ms | Tot: 15s813ms | Loss: 2.586 | Acc: 44.506% (2722/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      " [================================================================>]  Step: 39ms | Tot: 1m37s | Loss: 1.578 | Acc: 61.771% (15127/2448 383/383    \n",
      " [================================================================>]  Step: 123ms | Tot: 15s991ms | Loss: 2.553 | Acc: 45.307% (2771/611 96/96 \n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      " [=========>.......................................................]  Step: 47ms | Tot: 13s946ms | Loss: 1.425 | Acc: 65.148% (2460/377 59/383  \r"
     ]
    }
   ],
   "source": [
    "!python3 /home/cvblgita/akshay/AdaNorm-main/Caltech256/main_Caltech256.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 16s781ms | Tot: 16s781ms | Loss: 11.658 | Acc: 3.009% (184/611 96/96 \n",
      "Best Accuracy:  3.008502289077829\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 17s981ms | Tot: 17s981ms | Loss: 10.991 | Acc: 3.924% (240/611 96/96 \n",
      "Best Accuracy:  3.924133420536298\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s593ms | Tot: 19s593ms | Loss: 10.301 | Acc: 5.150% (315/611 96/96 \n",
      "Best Accuracy:  5.150425114453891\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s782ms | Tot: 19s782ms | Loss: 9.604 | Acc: 7.407% (453/611 96/96 \n",
      "Best Accuracy:  7.406801831262263\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s639ms | Tot: 20s639ms | Loss: 8.817 | Acc: 10.137% (620/611 96/96 \n",
      "Best Accuracy:  10.13734466971877\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 21s183ms | Tot: 21s183ms | Loss: 7.965 | Acc: 13.914% (851/611 96/96 \n",
      "Best Accuracy:  13.914323086984957\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 22s426ms | Tot: 22s426ms | Loss: 7.026 | Acc: 19.408% (1187/611 96/96 \n",
      "Best Accuracy:  19.408109875735775\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 22s198ms | Tot: 22s198ms | Loss: 6.076 | Acc: 26.112% (1597/611 96/96 \n",
      "Best Accuracy:  26.111837802485283\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 22s309ms | Tot: 22s309ms | Loss: 5.125 | Acc: 32.767% (2004/611 96/96 \n",
      "Best Accuracy:  32.76651406147809\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 21s861ms | Tot: 21s861ms | Loss: 4.310 | Acc: 39.536% (2418/611 96/96 \n",
      "Best Accuracy:  39.535644211903204\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s376ms | Tot: 20s376ms | Loss: 3.778 | Acc: 45.029% (2754/611 96/96 \n",
      "Best Accuracy:  45.02943100065402\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s50ms | Tot: 20s50ms | Loss: 3.645 | Acc: 46.632% (2852/611 96/96 \n",
      "Best Accuracy:  46.63178548070634\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s336ms | Tot: 20s336ms | Loss: 3.803 | Acc: 44.686% (2733/611 96/96 \n",
      "Best Accuracy:  44.6860693263571\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s381ms | Tot: 19s381ms | Loss: 4.369 | Acc: 38.833% (2375/611 96/96 \n",
      "Best Accuracy:  38.83257030739045\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s113ms | Tot: 20s113ms | Loss: 5.133 | Acc: 32.194% (1969/611 96/96 \n",
      "Best Accuracy:  32.194244604316545\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s467ms | Tot: 19s467ms | Loss: 6.026 | Acc: 25.768% (1576/611 96/96 \n",
      "Best Accuracy:  25.768476128188357\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s337ms | Tot: 20s337ms | Loss: 6.935 | Acc: 19.751% (1208/611 96/96 \n",
      "Best Accuracy:  19.7514715500327\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s597ms | Tot: 20s597ms | Loss: 7.814 | Acc: 14.241% (871/611 96/96 \n",
      "Best Accuracy:  14.241334205362982\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s819ms | Tot: 20s819ms | Loss: 8.634 | Acc: 10.121% (619/611 96/96 \n",
      "Best Accuracy:  10.120994113799869\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s452ms | Tot: 19s452ms | Loss: 9.386 | Acc: 7.162% (438/611 96/96 \n",
      "Best Accuracy:  7.161543492478744\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s593ms | Tot: 19s593ms | Loss: 10.033 | Acc: 5.298% (324/611 96/96 \n",
      "Best Accuracy:  5.297580117724003\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 20s276ms | Tot: 20s276ms | Loss: 10.637 | Acc: 4.137% (253/611 96/96 \n",
      "Best Accuracy:  4.136690647482014\n",
      "==> Preparing data..\n",
      "==> Building model..\n",
      " [================================================================>]  Step: 19s577ms | Tot: 19s577ms | Loss: 11.219 | Acc: 3.058% (187/611 96/96 \n",
      "Best Accuracy:  3.0575539568345325\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in np.array([-2.2,-2.0,-1.8,-1.6,-1.4,-1.2,-1.0,-0.8,-0.6,-0.4,-0.2,0.0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2]):\n",
    "    !python3 /home/cvblgita/akshay/AdaNorm-main/Caltech256/load.py {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPaXepTnmAK7EYujPxvpVWM",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
